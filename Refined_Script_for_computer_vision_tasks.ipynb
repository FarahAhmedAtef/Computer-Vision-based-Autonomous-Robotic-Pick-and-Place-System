{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP09DntK9KFntDkWopeDSPx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FarahAhmedAtef/Computer-Vision-based-Autonomous-Robotic-Pick-and-Place-System/blob/main/Refined_Script_for_computer_vision_tasks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8sri81FSqGm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import argparse\n",
        "import glob\n",
        "import time\n",
        "import difflib\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "\n",
        "import logging\n",
        "for handler in logging.root.handlers[:]:\n",
        "    logging.root.removeHandler(handler)\n",
        "\n",
        "logging.basicConfig(\n",
        "    stream=sys.stderr,\n",
        "    level=logging.DEBUG,\n",
        "    format='[%(asctime)s] %(name)s %(levelname)s: %(message)s'\n",
        ")\n",
        "\n",
        "logging.getLogger(\"ppocr\").setLevel(logging.DEBUG)\n",
        "logging.getLogger(\"ppocr\").propagate = True\n",
        "sys.stderr = open(os.devnull, 'w')\n",
        "def transform_point(image_point):\n",
        "\n",
        "    H = np.load(\"homography_matrix.npy\")\n",
        "    point = np.array([[[image_point[0], image_point[1]]]], dtype=np.float32)\n",
        "    world_point = cv2.perspectiveTransform(point, H)\n",
        "    return tuple(world_point[0][0])\n",
        "\n",
        "from paddleocr import PaddleOCR\n",
        "ocr = PaddleOCR(use_angle_cls=True, lang='en')  # Or 'de' for German, etc.\n",
        "\n",
        "def find_text_center_from_roi(frame, bbox_coords, classname):\n",
        "\n",
        "    x1, y1, x2, y2 = bbox_coords\n",
        "    roi = frame[y1:y2, x1:x2]\n",
        "    best_match = None\n",
        "    best_score = 0\n",
        "    best_box = None\n",
        "    besttext2 = None\n",
        "    bestbox2 = None\n",
        "\n",
        "    try:\n",
        "        result = ocr.ocr(roi, cls=True)\n",
        "\n",
        "        if result is not None and len(result) > 0:\n",
        "            for line in result[0]:\n",
        "                if not line or not isinstance(line, (list, tuple)) or len(line) < 2:\n",
        "                    continue\n",
        "\n",
        "                text = ''\n",
        "                if isinstance(line[1], (list, tuple)) and len(line[1]) > 0 and isinstance(line[1][0], str):\n",
        "                    text = line[1][0]\n",
        "\n",
        "\n",
        "                box = line[0]\n",
        "                #print(text)\n",
        "                score = difflib.SequenceMatcher(None, text.lower(), classname.lower()).ratio()\n",
        "                if score > best_score:\n",
        "                    best_score = score\n",
        "                    best_match = text\n",
        "                    best_box = box\n",
        "\n",
        "\n",
        "            if best_box is not None and best_score > 0.4:\n",
        "                #print('da difflib:' + best_match)\n",
        "                best_box = np.array(best_box, dtype=np.int32)\n",
        "                best_box[:, 0] += x1\n",
        "                best_box[:, 1] += y1\n",
        "                cv2.polylines(frame, [best_box], True, (0, 255, 0), 2)\n",
        "                center_x = int(np.mean(best_box[:, 0]))\n",
        "                center_y = int(np.mean(best_box[:, 1]))\n",
        "                return (center_x, center_y)\n",
        "            else:\n",
        "                if result is not None and len(result) > 0:\n",
        "                  for line in result[0]:\n",
        "                        if not line or not isinstance(line, (list, tuple)) or len(line) < 2:\n",
        "                            continue\n",
        "\n",
        "                        text = ''\n",
        "                        if isinstance(line[1], (list, tuple)) and len(line[1]) > 0 and isinstance(line[1][0], str):\n",
        "                            text = line[1][0]\n",
        "\n",
        "\n",
        "                        box = line[0]\n",
        "\n",
        "                        if classname.lower() == 'snickers':\n",
        "                            if 'sn' in text.lower() or 'ic' in text.lower() or 'ck' in text.lower() or 'ke' in text.lower() or 'er' in text.lower() or 'rs' in text.lower():\n",
        "                                #print('da el sec:'+ text)\n",
        "                                besttext2 = text.lower()\n",
        "                                bestbox2 = box\n",
        "\n",
        "                        elif classname == 'lion':\n",
        "                            if 's' not in text.lower():\n",
        "                                #print('right')\n",
        "                                if 'li' in text.lower() or 'io' in text.lower() or 'on' in text.lower() or 'no' in text.lower():\n",
        "                                    #print('da el sec:'+ text)\n",
        "                                    besttext2 = text.lower()\n",
        "                                    bestbox2 = box\n",
        "                        elif classname == 'mars':\n",
        "                            if 'rs' in text.lower() or 'w' in text.lower():\n",
        "                                #print('da el sec:'+ text)\n",
        "                                besttext2 = text.lower()\n",
        "                                bestbox2 = box\n",
        "                  if bestbox2 is not None:\n",
        "                    best_box = np.array(bestbox2, dtype=np.int32)\n",
        "                    best_box[:, 0] += x1\n",
        "                    best_box[:, 1] += y1\n",
        "                    cv2.polylines(frame, [best_box], True, (0, 255, 0), 2)\n",
        "                    center_x = int(np.mean(best_box[:, 0]))\n",
        "                    center_y = int(np.mean(best_box[:, 1]))\n",
        "                    return (center_x, center_y)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        return None\n",
        "\n",
        "    return None\n",
        "\n",
        "def compute_angle_from_frame(frame, center_x, center_y, w, h):\n",
        "\n",
        "    tl_x = int(center_x - w / 2)\n",
        "    tl_y = int(center_y - h / 2)\n",
        "\n",
        "    tl_x = max(0, tl_x)\n",
        "    tl_y = max(0, tl_y)\n",
        "    br_x = min(tl_x + w, frame.shape[1])\n",
        "    br_y = min(tl_y + h, frame.shape[0])\n",
        "\n",
        "    if tl_x >= br_x or tl_y >= br_y:\n",
        "        return None, None, None\n",
        "\n",
        "    roi = frame[tl_y:br_y, tl_x:br_x]\n",
        "\n",
        "\n",
        "    if roi.size == 0:\n",
        "        return None, None, None\n",
        "\n",
        "    mask = np.zeros(roi.shape[:2], np.uint8)\n",
        "    bgdModel = np.zeros((1, 65), np.float64)\n",
        "    fgdModel = np.zeros((1, 65), np.float64)\n",
        "    rect = (5, 5, roi.shape[1] - 10, roi.shape[0] - 10)\n",
        "\n",
        "    try:\n",
        "        cv2.grabCut(roi, mask, rect, bgdModel, fgdModel, 5, cv2.GC_INIT_WITH_RECT)\n",
        "    except:\n",
        "        return None, None, None\n",
        "\n",
        "    mask2 = np.where((mask == cv2.GC_FGD) | (mask == cv2.GC_PR_FGD), 1, 0).astype('uint8')\n",
        "    roi_seg = roi * mask2[:, :, np.newaxis]\n",
        "\n",
        "    gray_seg = cv2.cvtColor(roi_seg, cv2.COLOR_BGR2GRAY)\n",
        "    _, thresh_seg = cv2.threshold(gray_seg, 1, 255, cv2.THRESH_BINARY)\n",
        "    contours, _ = cv2.findContours(thresh_seg, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    angle = None\n",
        "    islongest = None\n",
        "    if not contours:\n",
        "        return None, None, None\n",
        "\n",
        "    largest_contour = max(contours, key=cv2.contourArea)\n",
        "    rect = cv2.minAreaRect(largest_contour)\n",
        "    (box_x, box_y), (rect_w, rect_h), angle = rect\n",
        "\n",
        "    if angle < -45:\n",
        "            side_length = rect_w\n",
        "    else:\n",
        "            side_length = rect_h\n",
        "\n",
        "\n",
        "    if angle < 0:\n",
        "            angle += 90\n",
        "    islongest = (side_length == max(rect_w, rect_h))\n",
        "\n",
        "    return angle,islongest\n",
        "\n",
        "\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--model', help='Path to YOLO model file (example: \"runs/detect/train/weights/best.pt\")',\n",
        "                    required=True)\n",
        "parser.add_argument('--source', help='Image source, can be image file (\"test.jpg\"), \\\n",
        "                    image folder (\"test_dir\"), video file (\"testvid.mp4\"), index of USB camera (\"usb0\"), or index of Picamera (\"picamera0\")',\n",
        "                    required=True)\n",
        "parser.add_argument('--thresh', help='Minimum confidence threshold for displaying detected objects (example: \"0.4\")',\n",
        "                    default=0.5)\n",
        "parser.add_argument('--resolution', help='Resolution in WxH to display inference results at (example: \"640x480\"), \\\n",
        "                    otherwise, match source resolution',\n",
        "                    default=None)\n",
        "parser.add_argument('--record', help='Record results from video or webcam and save it as \"demo1.avi\". Must specify --resolution argument to record.',\n",
        "                    action='store_true')\n",
        "\n",
        "args = parser.parse_args()\n",
        "\n",
        "\n",
        "model_path = args.model\n",
        "img_source = args.source\n",
        "min_thresh = args.thresh\n",
        "user_res = args.resolution\n",
        "record = args.record\n",
        "\n",
        "if (not os.path.exists(model_path)):\n",
        "    print('ERROR: Model path is invalid or model was not found. Make sure the model filename was entered correctly.' , file=sys.stderr)\n",
        "    sys.exit(0)\n",
        "\n",
        "model = YOLO(model_path, task='detect')\n",
        "labels = model.names\n",
        "\n",
        "img_ext_list = ['.jpg','.JPG','.jpeg','.JPEG','.png','.PNG','.bmp','.BMP']\n",
        "vid_ext_list = ['.avi','.mov','.mp4','.mkv','.wmv']\n",
        "\n",
        "if os.path.isdir(img_source):\n",
        "    source_type = 'folder'\n",
        "elif os.path.isfile(img_source):\n",
        "    _, ext = os.path.splitext(img_source)\n",
        "    if ext in img_ext_list:\n",
        "        source_type = 'image'\n",
        "    elif ext in vid_ext_list:\n",
        "        source_type = 'video'\n",
        "    else:\n",
        "        print(f'File extension {ext} is not supported.', file=sys.stderr)\n",
        "        sys.exit(0)\n",
        "elif 'usb' in img_source:\n",
        "    source_type = 'usb'\n",
        "    usb_idx = int(img_source[3:])\n",
        "elif 'picamera' in img_source:\n",
        "    source_type = 'picamera'\n",
        "    picam_idx = int(img_source[8:])\n",
        "else:\n",
        "    print(f'Input {img_source} is invalid. Please try again.' , file=sys.stderr)\n",
        "    sys.exit(0)\n",
        "\n",
        "resize = False\n",
        "if user_res:\n",
        "    resize = True\n",
        "    resW, resH = int(user_res.split('x')[0]), int(user_res.split('x')[1])\n",
        "\n",
        "if record:\n",
        "    if source_type not in ['video','usb']:\n",
        "        print('Recording only works for video and camera sources. Please try again.', file=sys.stderr)\n",
        "        sys.exit(0)\n",
        "    if not user_res:\n",
        "        print('Please specify resolution to record video at.', file=sys.stderr)\n",
        "        sys.exit(0)\n",
        "\n",
        "    record_name = 'demo1.avi'\n",
        "    record_fps = 30\n",
        "    recorder = cv2.VideoWriter(record_name, cv2.VideoWriter_fourcc(*'MJPG'), record_fps, (resW,resH))\n",
        "\n",
        "if source_type == 'image':\n",
        "    imgs_list = [img_source]\n",
        "elif source_type == 'folder':\n",
        "    imgs_list = []\n",
        "    filelist = glob.glob(img_source + '/*')\n",
        "    for file in filelist:\n",
        "        _, file_ext = os.path.splitext(file)\n",
        "        if file_ext in img_ext_list:\n",
        "            imgs_list.append(file)\n",
        "elif source_type == 'video' or source_type == 'usb':\n",
        "\n",
        "    if source_type == 'video': cap_arg = img_source\n",
        "    elif source_type == 'usb': cap_arg = usb_idx\n",
        "    cap = cv2.VideoCapture(cap_arg)\n",
        "\n",
        "    if user_res:\n",
        "        ret = cap.set(3, resW)\n",
        "        ret = cap.set(4, resH)\n",
        "\n",
        "elif source_type == 'picamera':\n",
        "    from picamera2 import Picamera2\n",
        "    cap = Picamera2()\n",
        "    cap.configure(cap.create_video_configuration(main={\"format\": 'RGB888', \"size\": (resW, resH)}, controls={\"FrameRate\": 50}))\n",
        "    cap.set_controls({\"ExposureTime\": 5000})\n",
        "    cap.start()\n",
        "\n",
        "bbox_colors = [(164,120,87), (68,148,228), (93,97,209), (178,182,133), (88,159,106),\n",
        "              (96,202,231), (159,124,168), (169,162,241), (98,118,150), (172,176,184)]\n",
        "\n",
        "avg_frame_rate = 0\n",
        "frame_rate_buffer = []\n",
        "fps_avg_len = 200\n",
        "img_count = 0\n",
        "frame_count=0\n",
        "while True:\n",
        "\n",
        "    t_start = time.perf_counter()\n",
        "\n",
        "    if source_type == 'image' or source_type == 'folder':\n",
        "        if img_count >= len(imgs_list):\n",
        "            print('All images have been processed. Exiting program.', file=sys.stderr)\n",
        "            sys.exit(0)\n",
        "        img_filename = imgs_list[img_count]\n",
        "        frame = cv2.imread(img_filename)\n",
        "        img_count = img_count + 1\n",
        "\n",
        "    elif source_type == 'video':\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            print('Reached end of the video file. Exiting program.', file=sys.stderr)\n",
        "            break\n",
        "\n",
        "    elif source_type == 'usb':\n",
        "        ret, frame = cap.read()\n",
        "        if (frame is None) or (not ret):\n",
        "            print('Unable to read frames from the camera. This indicates the camera is disconnected or not working. Exiting program.', file=sys.stderr)\n",
        "            break\n",
        "\n",
        "\n",
        "    elif source_type == 'picamera':\n",
        "        frame = cap.capture_array()\n",
        "        if frame is None:\n",
        "            print('Unable to read frames from the Picamera. This indicates the camera is disconnected or not working. Exiting program.', file=sys.stderr)\n",
        "            break\n",
        "        img_count=1\n",
        "    if resize:\n",
        "        frame = cv2.resize(frame, (resW, resH))\n",
        "\n",
        "\n",
        "        results = model(frame, verbose=False)\n",
        "\n",
        "\n",
        "\n",
        "    detections = results[0].boxes\n",
        "\n",
        "    object_count = 0\n",
        "    detection_results = []\n",
        "    STR = 'Logo recognition : fail'\n",
        "    for i in range(len(detections)):\n",
        "\n",
        "        xyxy_tensor = detections[i].xyxy.cpu()\n",
        "        xyxy = xyxy_tensor.numpy().squeeze()\n",
        "        xmin, ymin, xmax, ymax = xyxy.astype(int)\n",
        "\n",
        "        w = xmax - xmin\n",
        "        h = ymax - ymin\n",
        "        cx = (xmin + xmax) // 2\n",
        "        cy = (ymin + ymax) // 2\n",
        "        classidx = int(detections[i].cls.item())\n",
        "        classname = labels[classidx]\n",
        "\n",
        "        angle, is_longest= compute_angle_from_frame(frame, cx, cy, w, h)\n",
        "        classidx = int(detections[i].cls.item())\n",
        "        classname = labels[classidx]\n",
        "        ocr_center = find_text_center_from_roi(frame, (xmin, ymin, xmax, ymax), classname)\n",
        "\n",
        "        if ocr_center:\n",
        "            cx, cy = ocr_center\n",
        "            STR = 'Logo recognition : success'\n",
        "\n",
        "        dobot_center = transform_point((cx,cy))\n",
        "        cx,cy = dobot_center\n",
        "\n",
        "        conf = detections[i].conf.item()\n",
        "\n",
        "        if conf > 0.5:\n",
        "            detection_results.append({\n",
        "                \"class\": str(classname),\n",
        "                \"center_x\": int(round(cx)),\n",
        "                \"center_y\": int(round(cy)),\n",
        "                \"rotation\": bool(is_longest),\n",
        "                \"STR\": str(STR),\n",
        "                \"angle_deg\": int(round(angle)) if angle is not None else None\n",
        "            })\n",
        "        STR = 'Logo recognition : fail'\n",
        "    print(json.dumps(detection_results))\n",
        "\n",
        "    if img_count == 1:\n",
        "        print(\"First frame processed. Exiting script.\", file=sys.stderr)\n",
        "        sys.exit(0)\n",
        "\n",
        "\n",
        "print(f'Average pipeline FPS: {avg_frame_rate:.2f}', file=sys.stderr)\n",
        "if source_type == 'video' or source_type == 'usb':\n",
        "    cap.release()\n",
        "elif source_type == 'picamera':\n",
        "    cap.stop()\n",
        "if record: recorder.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# END"
      ],
      "metadata": {
        "id": "3I4fWpBffcYC"
      }
    }
  ]
}